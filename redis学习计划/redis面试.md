# Redis 实现数据去重的方法

Redis 提供了多种数据结构可以用来实现数据去重功能，以下是几种常见的方法：

## 1. 使用 Set 数据结构

Set 是 Redis 内置的去重集合，自动保证元素的唯一性。

```redis
SADD unique_set "item1"  # 添加元素
SADD unique_set "item2"
SISMEMBER unique_set "item1"  # 检查元素是否存在(1存在，0不存在)
```

## 2. 使用 Bitmap

对于整数型数据或可以转换为整数型的数据，可以使用 Bitmap 进行高效去重。

```redis
SETBIT unique_bitmap 123 1  # 将第123位设置为1
GETBIT unique_bitmap 123    # 检查第123位是否为1(1存在，0不存在)
```

## 3. 使用 HyperLogLog

适用于大数据量下的近似去重统计，占用空间极小但有一定误差率。

```redis
PFADD unique_hll "item1" "item2" "item3"  # 添加元素
PFCOUNT unique_hll  # 获取不重复元素数量
```

## 4. 使用 Bloom Filter (通过 RedisBloom 模块)

需要安装 RedisBloom 模块，提供高效的概率型去重。

```redis
BF.ADD unique_bf "item1"  # 添加元素
BF.EXISTS unique_bf "item1"  # 检查元素是否存在
```

## 5. 使用 Sorted Set

如果需要同时去重和排序，可以使用 Sorted Set。

```redis
ZADD unique_zset 1 "item1"  # 添加元素(分数可以是时间戳或其他值)
ZRANGE unique_zset 0 -1  # 获取所有元素
```

## 选择建议

- 精确去重且数据量不大：使用 **Set**
- 整数型数据去重：使用 **Bitmap**
- 大数据量近似统计：使用 **HyperLogLog**
- 大数据量精确去重：使用 **Bloom Filter**
- 需要排序的去重：使用 **Sorted Set**

根据你的具体场景(数据量、精确度要求、性能需求等)选择最适合的方法。



# Redis 各种去重方法的底层原理

下面我将详细解释 Redis 中各种去重方法的底层实现原理：

## 1. Set 数据结构

**底层实现**：
- 当元素较少且都是整数时，使用 **intset**（整数集合）实现
  - 一个连续内存数组，按从小到大排序
  - 查找使用二分查找，时间复杂度 O(log n)
- 当元素较多或包含非整数时，使用 **哈希表（hashtable）** 实现
  - Redis 的字典实现，使用链地址法解决哈希冲突
  - 平均时间复杂度 O(1)

**去重原理**：
- 哈希表的 key 就是集合元素，天然去重
- 插入前会先检查 key 是否已存在

## 2. Bitmap

**底层实现**：
- 本质上是字符串（SDS），每个字节的 8 位表示 8 个二进制位
- 自动扩展：当设置的位超出当前长度时自动扩容

**去重原理**：
- 每个元素映射为一个偏移量（offset）
- 该偏移量对应的 bit 位为 1 表示存在，0 表示不存在
- 适合处理整数型 ID 的去重

## 3. HyperLogLog

**底层实现**：
- 基于概率算法，使用 12KB 固定大小的空间
- 使用 16384 个 6bit 的寄存器（2^14 * 6bit = 12KB）
- 对输入元素做哈希，根据哈希值的前导零数量更新寄存器

**去重原理**：
- 利用哈希值的均匀分布特性
- 通过统计哈希值二进制表示中前导零的最大数量来估计基数
- 标准误差约为 0.81%

## 4. Bloom Filter (RedisBloom 模块)

**底层实现**：
- 底层也是使用 Bitmap（字符串）存储
- 使用多个不同的哈希函数

**去重原理**：
1. 添加元素时：
   - 对元素进行 k 个不同哈希函数计算
   - 将对应的 k 个位设置为 1
2. 检查元素时：
   - 检查所有 k 个位是否都为 1
   - 如果有任一位为 0，则肯定不存在
   - 如果全部为 1，则可能存在（存在误判）

## 5. Sorted Set

**底层实现**：
- 元素较少时使用 **ziplist**（压缩列表）
  - 一个连续内存块，按 score 排序存储
- 元素较多时使用 **跳跃表（skiplist）+ 哈希表** 的组合
  - 跳跃表用于按 score 排序和范围查询
  - 哈希表用于快速判断元素是否存在

**去重原理**：
- 哈希表保证元素的唯一性（member 作为 key）
- 跳跃表维护 score 排序关系

## 性能与存储对比

| 方法         | 精确性 | 空间复杂度      | 时间复杂度       | 适用场景           |
| ------------ | ------ | --------------- | ---------------- | ------------------ |
| Set          | 精确   | O(n)            | O(1)             | 小数据量精确去重   |
| Bitmap       | 精确   | O(max_offset)   | O(1)             | 整数ID去重         |
| HyperLogLog  | 近似   | 固定12KB        | O(1)             | 大数据量基数统计   |
| Bloom Filter | 概率   | O(n) 但系数很小 | O(k) k为哈希函数 | 大数据量存在性判断 |
| Sorted Set   | 精确   | O(n)            | O(log n)         | 需要排序的去重     |

理解这些底层原理可以帮助你根据具体场景选择最合适的去重方案。